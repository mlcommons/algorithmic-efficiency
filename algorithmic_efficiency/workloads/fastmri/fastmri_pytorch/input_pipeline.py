"""Data pipeline for FastMRI dataset.

Modified from:
https://github.com/facebookresearch/fastMRI/blob/main/fastmri/data
"""

import contextlib
import os
from pathlib import Path
import pickle
import random
from typing import Any, Callable, Dict, Optional, Sequence, Tuple, Union
import xml.etree.ElementTree as etree

import h5py
import numpy as np
import torch
from torch import Tensor

from algorithmic_efficiency.workloads.fastmri.fastmri_pytorch.fftc import \
    ifft2c_new


@contextlib.contextmanager
def temp_seed(rng: np.random.RandomState,
              seed: Optional[Union[int, Tuple[int, ...]]]) -> None:
  # A context manager for temporarily adjusting the random seed
  if seed is None:
    try:
      yield
    finally:
      pass
  else:
    state = rng.get_state()
    rng.seed(seed)
    try:
      yield
    finally:
      rng.set_state(state)


class RandomMask:

  def __init__(self,
               center_fractions: Sequence[float],
               accelerations: Sequence[int],
               seed: Optional[int] = None) -> None:
    self.center_fractions = center_fractions
    self.accelerations = accelerations
    self.rng = np.random.RandomState(seed)

  def __call__(
      self,
      shape: Sequence[int],
      seed: Optional[Union[int, Tuple[int, ...]]] = None
  ) -> Tuple[torch.Tensor, int]:
    if len(shape) < 3:
      raise ValueError('Shape should have 3 or more dimensions')

    with temp_seed(self.rng, seed):
      center_mask, accel_mask, num_low_frequencies = self.sample_mask(shape)

    # combine masks together
    return torch.max(center_mask, accel_mask), num_low_frequencies

  def sample_mask(
      self, shape: Sequence[int]) -> Tuple[torch.Tensor, torch.Tensor, int]:
    num_cols = shape[-2]
    center_fraction, acceleration = self.choose_acceleration()
    num_low_frequencies = round(num_cols * center_fraction)
    center_mask = self.reshape_mask(
        self.calculate_center_mask(shape, num_low_frequencies), shape)
    acceleration_mask = self.reshape_mask(
        self.calculate_acceleration_mask(num_cols,
                                         acceleration,
                                         num_low_frequencies),
        shape,
    )
    return center_mask, acceleration_mask, num_low_frequencies

  def reshape_mask(self, mask: np.ndarray,
                   shape: Sequence[int]) -> torch.Tensor:
    num_cols = shape[-2]
    mask_shape = [1 for _ in shape]
    mask_shape[-2] = num_cols
    return torch.from_numpy(mask.reshape(*mask_shape).astype(np.float32))

  def calculate_acceleration_mask(self,
                                  num_cols: int,
                                  acceleration: int,
                                  num_low_frequencies: int) -> np.ndarray:
    prob = (num_cols / acceleration - num_low_frequencies) / (
        num_cols - num_low_frequencies)
    return self.rng.uniform(size=num_cols) < prob

  def calculate_center_mask(self, shape: Sequence[int],
                            num_low_freqs: int) -> np.ndarray:
    num_cols = shape[-2]
    mask = np.zeros(num_cols, dtype=np.float32)
    pad = (num_cols - num_low_freqs + 1) // 2
    mask[pad:pad + num_low_freqs] = 1
    assert mask.sum() == num_low_freqs
    return mask

  def choose_acceleration(self):
    """Choose acceleration based on class parameters."""
    choice = self.rng.randint(len(self.center_fractions))
    return self.center_fractions[choice], self.accelerations[choice]


def to_tensor(data: np.ndarray) -> torch.Tensor:
  if np.iscomplexobj(data):
    data = np.stack((data.real, data.imag), axis=-1)
  return torch.from_numpy(data)


def apply_mask(
    data: torch.Tensor,
    mask_func: RandomMask,
    seed: Optional[Union[int, Tuple[int, ...]]] = None,
    padding: Optional[Sequence[int]] = None
) -> Tuple[torch.Tensor, torch.Tensor, int]:
  shape = (1,) * len(data.shape[:-3]) + tuple(data.shape[-3:])
  mask, num_low_frequencies = mask_func(shape, seed)
  if padding is not None:
    mask[:, :, :padding[0]] = 0
    # padding value inclusive on right of zeros
    mask[:, :, padding[1]:] = 0

  # the + 0.0 removes the sign of the zeros
  masked_data = data * mask + 0.0

  return masked_data, mask, num_low_frequencies


def center_crop(data: torch.Tensor, shape: Tuple[int, int]) -> torch.Tensor:
  if not (0 < shape[0] <= data.shape[-2] and 0 < shape[1] <= data.shape[-1]):
    raise ValueError('Invalid shapes.')

  w_from = (data.shape[-2] - shape[0]) // 2
  h_from = (data.shape[-1] - shape[1]) // 2
  w_to = w_from + shape[0]
  h_to = h_from + shape[1]
  return data[..., w_from:w_to, h_from:h_to]


def complex_center_crop(data: torch.Tensor, shape: Tuple[int,
                                                         int]) -> torch.Tensor:
  if not (0 < shape[0] <= data.shape[-3] and 0 < shape[1] <= data.shape[-2]):
    raise ValueError('Invalid shapes.')

  w_from = (data.shape[-3] - shape[0]) // 2
  h_from = (data.shape[-2] - shape[1]) // 2
  w_to = w_from + shape[0]
  h_to = h_from + shape[1]
  return data[..., w_from:w_to, h_from:h_to, :]


def normalize(data: torch.Tensor,
              mean: Union[float, torch.Tensor],
              stddev: Union[float, torch.Tensor],
              eps: Union[float, torch.Tensor] = 0.0) -> torch.Tensor:
  return (data - mean) / (stddev + eps)


def normalize_instance(
    data: torch.Tensor,
    eps: Union[float, torch.Tensor] = 0.0
) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
  mean = data.mean()
  std = data.std()
  return normalize(data, mean, std, eps), mean, std


def complex_abs(data: torch.Tensor) -> torch.Tensor:
  if not data.shape[-1] == 2:
    raise ValueError('Tensor does not have separate complex dim.')
  return (data**2).sum(dim=-1).sqrt()


class UnetDataTransform:

  def __init__(self,
               mask_func: Optional[RandomMask] = None,
               use_seed: bool = True) -> None:
    self.mask_func = mask_func
    self.use_seed = use_seed

  def __call__(
      self,
      kspace: np.ndarray,
      mask: np.ndarray,
      target: np.ndarray,
      attrs: Dict,
      fname: str,
      slice_num: int,
  ) -> Tuple[
      Any, Union[Tensor, Any], Tensor, Tensor, str, int, Union[float, Any]]:
    kspace_torch = to_tensor(kspace)

    # check for max value
    max_value = attrs['max'] if 'max' in attrs.keys() else 0.0

    # apply mask
    if self.mask_func:
      seed = None if not self.use_seed else tuple(map(ord, fname))
      # we only need first element, which is k-space after masking
      masked_kspace = apply_mask(kspace_torch, self.mask_func, seed=seed)[0]
    else:
      masked_kspace = kspace_torch

    # inverse Fourier transform to get zero filled solution
    image = ifft2c_new(masked_kspace)

    # crop input to correct size
    if target is not None:
      crop_size = (target.shape[-2], target.shape[-1])
    else:
      crop_size = (attrs['recon_size'][0], attrs['recon_size'][1])

    # check for FLAIR 203
    if image.shape[-2] < crop_size[1]:
      crop_size = (image.shape[-2], image.shape[-2])

    image = complex_center_crop(image, crop_size)

    # absolute value
    image = complex_abs(image)

    # normalize input
    image, mean, std = normalize_instance(image, eps=1e-11)
    image = image.clamp(-6, 6)

    # normalize target
    if target is not None:
      target_torch = to_tensor(target)
      target_torch = center_crop(target_torch, crop_size)
      target_torch = normalize(target_torch, mean, std, eps=1e-11)
      target_torch = target_torch.clamp(-6, 6)
    else:
      target_torch = torch.Tensor([0])

    return image, target_torch, mean, std, fname, slice_num, max_value


def et_query(root: etree.Element,
             qlist: Sequence[str],
             namespace: str = 'http://www.ismrm.org/ISMRMRD') -> str:
  s = '.'
  prefix = 'ismrmrd_namespace'

  ns = {prefix: namespace}

  for el in qlist:
    s = s + f'//{prefix}:{el}'

  value = root.find(s, ns)
  if value is None:
    raise RuntimeError('Element not found')

  return str(value.text)


class SliceDataset(torch.utils.data.Dataset):
  """
  A PyTorch Dataset that provides access to MR image slices.
  """

  def __init__(
      self,
      root: Union[str, Path, os.PathLike],
      transform: Optional[Callable] = None,
      use_dataset_cache: bool = False,
      dataset_cache_file: Union[str, Path, os.PathLike] = 'dataset_cache.pkl',
  ):
    self.dataset_cache_file = Path(dataset_cache_file)

    self.transform = transform
    self.recons_key = 'reconstruction_esc'
    self.examples = []

    # set default sampling mode
    sample_rate = 1.0
    volume_sample_rate = 1.0

    # load dataset cache if user wants to use it
    if self.dataset_cache_file.exists() and use_dataset_cache:
      with open(self.dataset_cache_file, 'rb') as f:
        dataset_cache = pickle.load(f)
    else:
      dataset_cache = {}

    # check if our dataset is in the cache
    # if there, use that metadata, if not, then regenerate the metadata
    if dataset_cache.get(root) is None or not use_dataset_cache:
      files = list(Path(root).iterdir())
      for fname in sorted(files):
        metadata, num_slices = self._retrieve_metadata(fname)

        self.examples += [
            (fname, slice_ind, metadata) for slice_ind in range(num_slices)
        ]

      if dataset_cache.get(root) is None and use_dataset_cache:
        dataset_cache[root] = self.examples
        print(f'Saving dataset cache to {self.dataset_cache_file}.')
        with open(self.dataset_cache_file, 'wb') as cache_f:
          pickle.dump(dataset_cache, cache_f)
    else:
      print(f'Using dataset cache from {self.dataset_cache_file}.')
      self.examples = dataset_cache[root]

    # subsample if desired
    if sample_rate < 1.0:  # sample by slice
      random.shuffle(self.examples)
      num_examples = round(len(self.examples) * sample_rate)
      self.examples = self.examples[:num_examples]
    elif volume_sample_rate < 1.0:  # sample by volume
      vol_names = sorted(list(set([f[0].stem for f in self.examples])))
      random.shuffle(vol_names)
      num_volumes = round(len(vol_names) * volume_sample_rate)
      sampled_vols = vol_names[:num_volumes]
      self.examples = [
          example for example in self.examples
          if example[0].stem in sampled_vols
      ]

  def _retrieve_metadata(self, file_name):
    with h5py.File(file_name, 'r') as hf:
      et_root = etree.fromstring(hf['ismrmrd_header'][()])

      enc = ['encoding', 'encodedSpace', 'matrixSize']
      enc_size = (
          int(et_query(et_root, enc + ['x'])),
          int(et_query(et_root, enc + ['y'])),
          int(et_query(et_root, enc + ['z'])),
      )
      rec = ['encoding', 'reconSpace', 'matrixSize']
      recon_size = (
          int(et_query(et_root, rec + ['x'])),
          int(et_query(et_root, rec + ['y'])),
          int(et_query(et_root, rec + ['z'])),
      )

      lims = ['encoding', 'encodingLimits', 'kspace_encoding_step_1']
      enc_limits_center = int(et_query(et_root, lims + ['center']))
      enc_limits_max = int(et_query(et_root, lims + ['maximum'])) + 1

      padding_left = enc_size[1] // 2 - enc_limits_center
      padding_right = padding_left + enc_limits_max

      num_slices = hf['kspace'].shape[0]

    metadata = {
        'padding_left': padding_left,
        'padding_right': padding_right,
        'encoding_size': enc_size,
        'recon_size': recon_size,
    }

    return metadata, num_slices

  def __len__(self):
    return len(self.examples)

  def __getitem__(self, i: int):
    fname, dataslice, metadata = self.examples[i]

    with h5py.File(fname, 'r') as hf:
      kspace = hf['kspace'][dataslice]

      mask = np.asarray(hf['mask']) if 'mask' in hf else None

      target = hf[self.recons_key][dataslice] if self.recons_key in hf else None

      attrs = dict(hf.attrs)
      attrs.update(metadata)

    if self.transform is None:
      sample = (kspace, mask, target, attrs, fname.name, dataslice)
    else:
      sample = self.transform(kspace,
                              mask,
                              target,
                              attrs,
                              fname.name,
                              dataslice)

    return sample
